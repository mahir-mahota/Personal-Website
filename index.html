<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      name="description"
      content="Here's my digital portfolio, where you can learn all about my projects and past experiences!"
    />
    <meta name="author" content="Mahir Mahota" />
    <link rel="icon" href="./assets/favicon.ico" sizes="any" />
    <title>Mahir Mahota</title>
    <link rel="stylesheet" href="/styles/styles.css" />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.css"
    />
    <script defer src="script.js"></script>
  </head>
  <body>
    <section id="cover">
      <video autoplay loop muted id="video">
        <source src="./assets/background.mp4" type="video/mp4" />
      </video>
      <h1 class="hidden">HI, I'M MAHIR!</h1>
      <a href="#about" class="arrow-container">
        <div class="arrow"></div>
        <div class="arrow"></div>
        <div class="arrow"></div>
      </a>
    </section>

    <nav id="nav" class="inactive">
      <ul>
        <li class="logo">
          <a href="#">
            <!-- <img class="logo" src="./assets/Logo" alt="Logo" /> -->
            <p class="logo">M</p>
          </a>
        </li>
        <li class="text"><a href="#about">About</a></li>
        <li class="text"><a href="#projects">Projects</a></li>
        <li class="text"><a href="#experience">Experience</a></li>
        <li class="text">
          <a href="./assets/Mahir Mahota Résumé.pdf" target="_blank">Résumé</a>
        </li>
        <li class="button-container">
          <a
            class="fab fa-linkedin fa-lg button"
            href="https://www.linkedin.com/in/mahir-mahota"
            target="_blank"
          >
          </a>
          <a
            class="fab fa-github fa-lg button"
            href="https://github.com/mahir-mahota"
            target="_blank"
          >
          </a>
          <a
            class="fas fa-envelope fa-lg button"
            href="mailto: mmahota@uwaterloo.ca"
          >
          </a>
        </li>
        <button
          class="menu bars"
          onclick="this.classList.toggle('opened');this.setAttribute('aria-expanded', this.classList.contains('opened'))"
          aria-label="Main Menu"
        >
          <svg
            width="35"
            height="35"
            viewBox="0 0 100 100"
            style="background-color: hsl(0 0% 0% / 0.7)"
            user-select="none"
          >
            <path
              class="line line1"
              d="M 20,29.000046 H 80.000231 C 80.000231,29.000046 94.498839,28.817352 94.532987,66.711331 94.543142,77.980673 90.966081,81.670246 85.259173,81.668997 79.552261,81.667751 75.000211,74.999942 75.000211,74.999942 L 25.000021,25.000058"
            />
            <path class="line line2" d="M 20,50 H 80" />
            <path
              class="line line3"
              d="M 20,70.999954 H 80.000231 C 80.000231,70.999954 94.498839,71.182648 94.532987,33.288669 94.543142,22.019327 90.966081,18.329754 85.259173,18.331003 79.552261,18.332249 75.000211,25.000058 75.000211,25.000058 L 25.000021,74.999942"
            />
          </svg>
        </button>
      </ul>
    </nav>

    <section id="about">
      <div class="text-container">
        <h2 class="about-title">About Me</h2>
        <p>
          I'm a second year Mechatronics Engineering student at the University
          of Waterloo. Motivated by curiosity, I started experimenting with
          electronics and robotics at a young age. From there grew a strong
          interest in all things related to embedded software and machine
          learning. My name translates to 'skillful' and this is a word I try to
          embody in my daily life by always striving to learn and grow. I'm
          currently on co-op as an Embedded Software Developer at Christie
          Digital Systems. Outside of work I like playing squash, chess and
          speedcubing. I enjoy working on new projects and you can find out all
          about them below!
        </p>
      </div>
      <img src="./assets/me.png" alt="me" />
    </section>

    <section id="projects">
      <h2 class="project-title">Projects</h2>

      <div class="cards-container">
        <span class="project-arrow arrow-left"></span>

        <div class="card arm-card card1">
          <div class="overlay">
            <h3>Gesture Controlled Robotic Arm</h3>
          </div>
          <span class="project-close"></span>
          <img class="img" src="./assets/arm.png" />
          <span class="content">
            <p>
              What started as an ordinary 6 domains of freedom robotic arm
              turned into my dive into computer vision and the amazing world of
              image recognition using OpenCV. I used Google's MediaPipe library
              to place 21 landmarks onto my hand, each with individual
              coordinates relative to the frame. These could then be transferred
              into an array and used to detect when specific finger or palm
              positioning changed.
            </p>
            <p>
              I detected these changes to define commands related to various
              hand gestures. The PySerial library was used to then send these
              from the python program to the Arduino through serial
              communication over an HC-06 Bluetooth module. After the hand was
              calibrated by being held up for 30 frames, the C++ program on the
              Arduino routinely polled the serial port to see if any commands
              were queued and then executed them accordingly.
            </p>
            <p>
              The six servo motors were wired to two external power supplies on
              a breadboard to properly support their stall current. The ground
              wires of the motors and the power supplies were also soldered
              together with the ground on the Arduino. All of the wiring was
              then neatly hidden inside an acrylic base cut out using a bandsaw
              and then drilled together.
            </p>
          </span>
          <iframe
            class="video"
            src="https://www.youtube.com/embed/djcaYWz_wmY?rel=0"
            title="YouTube video player"
            frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
            allowfullscreen
          ></iframe>
        </div>

        <!-- <div class="card brick-card card2">
          <div class="overlay">
            <h3>Brick Scanner</h3>
          </div>
          <span class="project-close"></span>
          <img class="img" src="" />
          <span class="content">
            <p></p>
          </span>
          <iframe
            class="video"
            src=""
            title="YouTube video player"
            frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
            allowfullscreen
          ></iframe>
        </div> -->

        <div class="card htn23-card card3">
          <div class="overlay">
            <h3>Eye Controlled Trolley</h3>
          </div>
          <span class="project-close"></span>
          <img class="img" src="./assets/htn23.png" />
          <span class="content">
            <p>
              This was the project our team of 4 developed over Hack the North
              2023. I programmed an ESP32 to drive 4 DC motors through L298N
              H-bridges, enabling speed control through a phone or laptop over
              WiFi. Data from a MPU6050 gyroscope was also processed to keep
              track of what way the trolley was facing relative to its desired
              direction. This allowed turning to be done autonomously after a
              move command was processed. All of the components were then wired
              together and soldered before being attached to the underside of a
              3D printed chassis.
            </p>
            <p>
              We also interfaced with AdHawk eye tracking glasses and their API
              in Python to detect blinks and monitor gaze coordinates with 80%
              accuracy, allowing the distance between points around the user to
              be calculated. Double blinks were used to lock in a point and two
              double blinks in a row would signify that the user wanted the
              trolley to traverse the distance between them. Lastly, sockets
              were used to connect the Python program with the ESP32 so that
              commands could be sent properly.
            </p>
          </span>
        </div>

        <div class="card ev3-card card4">
          <div class="overlay">
            <h3>Guitar Playing Robot</h3>
          </div>
          <span class="project-close"></span>
          <img class="img" src="./assets/ev3.png" />
          <span class="content">
            <p>
              This was the result of the final project for our first year
              digital computation course. The robot plays a string on a guitar
              by reading the notes in through a coloured strip. The strip itself
              is constructed using a C++ program that converts a MIDI file into
              colour coded squares. This is then passed into a gear mechanism
              that rolls the strip through, passing it under various sensors for
              detecting input.
            </p>
            <p>
              I wrote functions in C to take input from colour and ultrasonic
              sensors for accurately tracking task completion. Output from
              onboard motor encoders was processed to play songs with up to five
              frets. The fret playing mechanism consisted of a cam shaft that
              rotated and pressed down on the string in different areas
              depending on the angle of rotation. I wrote and optimised nine
              different functions to work in sync together so that there was no
              noticeable delay or lack of clarity in the notes. More information
              can be found in the report
              <a
                href="./assets/The sEV3n Nation Army Report.pdf"
                target="_blank"
                >here</a
              >.
            </p>
          </span>
          <iframe
            class="video"
            src="https://www.youtube.com/embed/CBR8fKITXuw?rel=0"
            title="YouTube video player"
            frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
            allowfullscreen
          ></iframe>
        </div>

        <div class="card discord-card card5">
          <div class="overlay">
            <h3>Movie Reviews Discord Bot</h3>
          </div>
          <span class="project-close"></span>
          <img class="img" src="./assets/discord.png" />
          <span class="content">
            <p>
              Implemented text vectorisation to do sentiment analysis of movie
              reviews with 98% accuracy. Designed, trained, and tested the
              neural network for NLP with TensorFlow, using a dataset of 50K
              IMDb reviews. Pre-processed the data using Pandas and prepared it
              by vectorising and creating an input pipeline, separating
              training, validation, and testing sets. Graphed the loss and
              accuracy of the model over time using Matplotlib to detect any
              discrepancies.
            </p>
            <p>
              I created a Python web-scraper using BeautifulSoup4 to search a
              query on Google and extract text from the top ten results. I then
              developed a bot using the Python Discord API to interact with the
              user, taking in a movie name and running the web-scraper after the
              program searches it up. The content of the articles returned is
              then passed into the model to predict whether reviews are positive
              or not. The verdict is then given to the user in the chat
              interface.
            </p>
          </span>
        </div>

        <div class="card tic-card card6">
          <div class="overlay">
            <h3>Wheel Tracking Algorithm</h3>
          </div>
          <span class="project-close"></span>
          <img class="img" src="./assets/tic.png" />
          <span class="content">
            <p>
              This was a result of the two Toyota Innovation Challenges held at
              the university. The first one was to program a solution for taking
              images of cars at the right time on a conveyor belt, for quality
              control. The aim was to detect the wheels with OpenCV computer
              vision instead of the current standard of mechanical triggers, to
              improve accuracy.
            </p>
            <p>
              We developed a successful program in under 12 hours using OpenCV
              code snippets, such as Hough transform and contour detection
              functions. This was done collaboratively in a Jupyter Notebook
              amongst a group of four. Both wheels are detected, and the front
              one is bounded using a red square. When the front wheel passes a
              certain point (denoted by the vertical red line), an image is
              taken and saved. The code was tested on a scaled down model of the
              factory system
            </p>
            <p>
              The second challenge consisted of detecting the holes on vehicle
              bodies that TMMC covers with stickers to prevent water leakage and
              wind noise. This is usually done using a robotic arm equipped with
              a camera and the goal was for our program to be able to detect
              when a sticker was properly applied or not. I was successfully the
              only one able to make the depth camera program function inside WSL
              Ubuntu and our program worked well as intended, winning a Co-op's
              Choice Award.
            </p>
          </span>
          <iframe
            class="video"
            src="https://www.youtube.com/embed/STk9KcRa3g0?rel=0"
            title="YouTube video player"
            frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
            allowfullscreen
          ></iframe>
        </div>

        <span class="project-arrow arrow-right"></span>
      </div>
    </section>

    <section id="experience">
      <h2 class="experience-title">Experience</h2>

      <div class="timeline-container">
        <div class="timeline">
          <ul>
            <li>
              <div class="timeline-content">
                <h3 class="date">January 2024 - Present</h3>
                <h4>Embedded Software Developer</h4>
                <p>Christie Digital Systems</p>
              </div>
            </li>

            <li>
              <div class="timeline-content">
                <h3 class="date">May 2023 - August 2023</h3>
                <h4>Firmware Developer</h4>
                <p>onsemi</p>
              </div>
            </li>

            <li>
              <div class="timeline-content">
                <h3 class="date">June 2023 - Present</h3>
                <h4>Firmware Team Lead</h4>
                <p>Waterloop</p>
              </div>
            </li>

            <li>
              <div class="timeline-content">
                <h3 class="date">September 2022 - April 2023</h3>
                <h4>Embedded Flight Software Member</h4>
                <p>Waterloo Aerial Robotics Group</p>
              </div>
            </li>

            <li>
              <div class="timeline-content">
                <a
                  href="./assets/Mahir Mahota Résumé.pdf"
                  target="_blank"
                  class="resume"
                >
                  <h4>
                    <i class="fa fa-external-link resume-icon"></i>
                  </h4>
                  <h4 class="resume-text">Résumé</h4>
                </a>
              </div>
            </li>
          </ul>
        </div>
      </div>
    </section>

    <section id="footer"><h2>Copyright &copy 2023 Mahir Mahota</h2></section>
  </body>
</html>
